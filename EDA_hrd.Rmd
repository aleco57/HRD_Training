---
title: "EDA_hrd"
output: html_document
---

Data Exploration
Linear regression with continuous GIS outcome  
XGBOOST with continuous GIS  
Split data by GIS 0-33 33-42 42+, see if this could be modeled  
Split data to binary (using 33 and 42 as the two thresholds)  
SHAP plots

```{r setup, include=FALSE}
library(janitor)
library(dlookr)
library(dplyr)
library(ggplot2)
library(SmartEDA)
library(GGally)
library(tidymodels)
library(caret)
library(SHAPforxgboost)


clean <- readxl::read_xls("~/Documents/D6_all_training.xls")
clean <- clean_names(clean)
```

Check for missing or duplicate data:

```{r, Missing Data, warning=FALSE, messgae=F}
cleanP <- subset(clean, select=-c(sample_id, brc_am, hrd_status, pd_l1_thr1, pd_l1_thr2))
#We can categorise patients into those who passed the gis threshold of 51
clean <- clean %>% mutate(gis_score_cat = cut(clean$gis_score, breaks=c(-Inf, 33, 51,Inf),
              labels=c("<33", ">=33, <=51", ">51")))
cleanP2 <- subset(clean, select=-c(sample_id, brc_am, hrd_status, pd_l1_thr1, pd_l1_thr2, gis_score)) 


#Change to factor variables
clean[,c(7:9,11:12)] <- lapply(clean[,c(7:9,11:12)] , factor)

table(clean$gis_score_cat)
#Slight imbalance of individuals in the middle group

#We can see how the mean alters for each of our categories
sapply(cleanP2[-6], tapply, INDEX=cleanP2$gis_score_cat, mean)



#Explore those individuals who have brca mutation but low gis_score
clean %>% filter(brc_am==1 & gis_score <=42)
clean %>% filter(brc_am==1 & gis_score <33)
#There are 4 patients who do not meet the threshold however brca test is positive.

get_dupes(clean)
glimpse(clean)
diagnose(clean)
diagnose_numeric(clean)
#No missing data present

```

```{r, warning=FALSE, messgae=F}
#Correlation Coeficent for all gis
cleanP %>% correlate() %>% plot()

#Correlation coefficent for gis split into the three groups
clean %>% group_by(gis_score_cat) %>% correlate() %>% plot()

ExpNumViz(cleanP, target="gis_score")
#Doesn't seem to be much of a linear relationship with cont_gis and any of our variables

ExpCatStat(cleanP, Target="gis_score", Pclass="1", plot=TRUE)
#Chi sqaured statistic does however suggest some degree of "information value for cont_gis and the variables

#Check for normality of our cont variables
cleanP %>% normality()
cleanP %>% plot_normality()
```

Doesn't seem to be much of a linear relationship with any of a variables, however we will still start with linear regression

Normality plots suggests necrosis%, surface area and pdl1 should be logged to approach normality

First model the continuous gis outcome with linear regression analyses:

```{r, Model Continuous Outcome, warning=FALSE, messgae=F}
#Split data into test and train
set.seed(122)
trainIndex <- createDataPartition(cleanP$gis_score, 
                                  list=F,
                                  p=.8)
Train <- cleanP[ trainIndex,]
Test  <- cleanP[-trainIndex,]

#Linear regression with all continuous variables
mod_lin1 <- train(gis_score ~ ., 
                  data=Train,
                  method = "lm")

summary(mod_lin1)
pred_lin1 <- mod_lin1 %>% predict(Test)
plot(pred_lin1, Test$gis_score)
R2(pred_lin1, Test$gis_score)
RMSE(pred_lin1, Test$gis_score)
#Poor Predictive value


#necrosis, surface_area and pd_l1 could be logged as the normality plots suggested
rec_lin2 <- recipe(gis_score ~ ., data=Train) %>%  step_log(necrosis_percent, surface_area_mm_2, pd_l1_cont_score, offset = 1) 
mod_lin2 <- train(rec_lin2, 
                  data = Train,
                  method = "lm")
summary(mod_lin2)
pred_lin2 <- predict(mod_lin2, Test) 
plot(pred_lin2, Test$gis_score)
R2(pred_lin2, Test$gis_score)
RMSE(pred_lin2, Test$gis_score)
#Model R2 Test 1% better then previous


#Use the three most significant variables from the model keeping onto the pre-processing step
rec_lin3 <- recipe(gis_score ~ age + pd_l1_cont_score + surface_area_mm_2, data=Train) %>%  
  step_log(surface_area_mm_2, pd_l1_cont_score, offset = 1) 
mod_lin3 <- train(rec_lin3, 
                  data = Train,
                  method = "lm")

summary(mod_lin3)
pred_lin3 <- predict(mod_lin3, Test) 
plot(pred_lin3, Test$gis_score)
R2(pred_lin3, Test$gis_score)
RMSE(pred_lin3, Test$gis_score)

#Similar results when only using the three variables in a linear model
```
Next, lets run xgboost for the model

```{r, warning=FALSE, messgae=F}
#mod_xgb1 <-  train(gis_score ~ ., 
 #                  data=Train,
  #                 method = "xgbTree",
   #                trControl = trainControl("cv", number = 5),
    #               tuneGrid = expand.grid(nrounds = c(500,1000,1500),
     #                                     eta = c(0.1,.03,.05),
      #                                    gamma = c(0,50),
       #                                   max_depth = c(1, 3, 5),
        #                                  min_child_weight= c(0,10),
         #                                 subsample = c(0.5,1),
          #                                colsample_bytree = c(0.5,1))
           #        )
#plot(mod_xgb1)
mod_xgb1$bestTune
mod_xgb1$results[order(mod_xgb1$results$RMSE),] %>% head()

pred_xgb1 <- predict(mod_xgb1, Test) 
#plot(pred_xgb1, Test$gis_score)
R2(pred_xgb1, Test$gis_score)
RMSE(pred_xgb1, Test$gis_score)

#Seem to be better performance for xgboost, but r2 still low

```

We can also run a xgbmodel by splitting the gis into the three categories as previously mentioned.
However, there didn't seem to be a huge difference betwen the bottom and middle group in terms of means of the other variables,
AND we have a much smaller sample for our middle group which could be biasing estimates

```{r, warning=FALSE, message=FALSE}
set.seed(122)
trainIndex2 <- createDataPartition(cleanP2$gis_score_cat, 
                                  list=F,
                                  p=.8)
TrainClass <- cleanP2[ trainIndex2,]
TestClass  <- cleanP2[-trainIndex2,]

#mod_xgbClass <-  train(gis_score_cat ~ ., 
 #                  data=TrainClass,
  #                 method = "xgbTree",
   #                trControl = trainControl("cv", number = 5),
    #               tuneGrid = expand.grid(nrounds = c(500,1000,1500),
     #                                     eta = c(0.1,.03,.05),
      #                                    gamma = c(0,50),
       #                                   max_depth = c(1, 3, 5),
        #                                  min_child_weight= c(0,10),
         #                                 subsample = c(0.5,1),
          #                                colsample_bytree = c(0.5,1))
           #        )
#plot(mod_xgbClass)
mod_xgbClass$bestTune
mod_xgbClass$results[order(mod_xgbClass$results$Kappa),] %>% head()

pred_xgbClass <- predict(mod_xgbClass, TestClass) 
confusionMatrix(pred_xgbClass, TestClass$gis_score_cat)

```

As suspected, model struggles to discriminate the middle category, therefore lets run xgboost and logistic regression for two thresholds in the literature (33 & 42)

```{r, warning=FALSE, messgae=F}
clean$gis33 <- factor(ifelse(clean$gis_score < 33, "<33", ">=33"))
clean$gis42 <- factor(ifelse(clean$gis_score < 42, "<42", ">=42"))

cleanP3 <- subset(clean, select=-c(sample_id, brc_am, hrd_status, pd_l1_thr1, pd_l1_thr2, gis_score, gis_score_cat)) 
set.seed(122)
trainIndex3 <- createDataPartition(cleanP3$gis33, 
                                  list=F,
                                  p=.8)
TrainBinary <- cleanP3[ trainIndex3,]
TestBinary  <- cleanP3[-trainIndex3,]

mod_log33 <- train(gis33 ~ . - gis42, 
                   data=TrainBinary,
                   method = "glm",
                   family = "binomial",
                   trControl = trainControl("cv", number = 5))
summary(mod_log33)
pred_log33 <- predict(mod_log33, TestBinary) 
confusionMatrix(pred_log33, TestBinary$gis33)

#mod_xgb33 <-  train(gis33 ~ . - gis42, 
 #                  data=TrainBinary,
  #                 method = "xgbTree",
   #                trControl = trainControl("cv", number = 5),
    #               tuneGrid = expand.grid(nrounds = c(500,1000,1500),
     #                                     eta = c(0.1,.03,.05),
      #                                    gamma = c(0,50),
       #                                   max_depth = c(1, 3, 5),
        #                                  min_child_weight= c(0,10),
         #                                 subsample = c(0.5,1),
          #                                colsample_bytree = c(0.5,1))
           #        )
#plot(mod_xgb33)
mod_xgb33$bestTune
mod_xgb33$results[order(mod_xgb33$results$Kappa),] %>% head()

pred_xgb33 <- predict(mod_xgb33, TestBinary) 
confusionMatrix(pred_xgb33, TestBinary$gis33)
#Logistic regression model seems to perform better than trained xgboost model



#Now repeat with 42 threshold
mod_log42 <- train(gis42 ~ . - gis33, 
                   data=TrainBinary,
                   method = "glm",
                   family = "binomial",
                   trControl = trainControl("cv", number = 5))
summary(mod_log42)
pred_log42 <- predict(mod_log42, TestBinary) 
confusionMatrix(pred_log42, TestBinary$gis42)

#mod_xgb42 <-  train(gis42 ~ . - gis33, 
 #                  data=TrainBinary,
  #                 method = "xgbTree",
   #                trControl = trainControl("cv", number = 5),
    #               tuneGrid = expand.grid(nrounds = c(500,1000,1500),
     #                                     eta = c(0.1,.03,.05),
      #                                    gamma = c(0,50),
       #                                   max_depth = c(1, 3, 5),
        #                                  min_child_weight= c(0,10),
         #                                 subsample = c(0.5,1),
          #                                colsample_bytree = c(0.5,1))
           #        )
#plot(mod_xgb42)
mod_xgb42$bestTune
mod_xgb42$results[order(mod_xgb42$results$Kappa),] %>% head()

pred_xgb42 <- predict(mod_xgb42, TestBinary) 
confusionMatrix(pred_xgb42, TestBinary$gis42)

#Highest predictive value comes from logistic regression model with 42 threshold
```

```{r}
ROC_binary42 <- pROC::roc(TestBinary$gis42, as.ordered(pred_log42),
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)

ROC_binary42 <- pROC::roc(TestBinary$gis42, as.ordered(pred_xgb42),
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)


clean %>%
  ggplot(aes(x=gis_score))+
  geom_histogram(aes(y =..density..),
                 bins=50,
                 color="black", 
                 fill="dodgerblue") +
   geom_density(col=3) +
  geom_vline(aes(xintercept= 42),
            color="red",  size=1)
  labs(title="Distribution of GIS score",
         x= "GIS score")
  
  clean$highlight <- ifelse(clean$gis_score<42 & clean$hrd_status==1, 0, 1)
  
clean %>%
  ggplot(aes(hrd_status, gis_score, colour=highlight))+ 
  geom_boxplot()+
   geom_hline(aes(yintercept= 42),
            color="red",  size=1) +
  geom_jitter(width = 0.2) +
  theme(legend.position="none")
 
```
